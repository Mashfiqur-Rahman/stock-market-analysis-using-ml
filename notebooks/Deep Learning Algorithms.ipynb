{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2cc6b1c",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b72930f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, GRU, SimpleRNN, Conv1D\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)\n",
    "plt.rcParams.update({'figure.figsize': (16, 9)})\n",
    "import matplotlib\n",
    "import sklearn\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75d0fe1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ta\n",
      "  Downloading ta-0.7.0.tar.gz (25 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\mashfiqur\\anaconda3\\envs\\mlpy38\\lib\\site-packages (from ta) (1.19.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\mashfiqur\\anaconda3\\envs\\mlpy38\\lib\\site-packages (from ta) (1.2.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\mashfiqur\\anaconda3\\envs\\mlpy38\\lib\\site-packages (from pandas->ta) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\mashfiqur\\anaconda3\\envs\\mlpy38\\lib\\site-packages (from pandas->ta) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mashfiqur\\anaconda3\\envs\\mlpy38\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->ta) (1.16.0)\n",
      "Building wheels for collected packages: ta\n",
      "  Building wheel for ta (setup.py): started\n",
      "  Building wheel for ta (setup.py): finished with status 'done'\n",
      "  Created wheel for ta: filename=ta-0.7.0-py3-none-any.whl size=28718 sha256=1f29583a73f835cb3f051ccef121fbdd9aedf7555dce2c7849aa6b5f34f95ed8\n",
      "  Stored in directory: c:\\users\\mashfiqur\\appdata\\local\\pip\\cache\\wheels\\bb\\7c\\a0\\9c72e50ddef1f7c3d9003bf4ccc5d5c8deb24828d4eb156fc8\n",
      "Successfully built ta\n",
      "Installing collected packages: ta\n",
      "Successfully installed ta-0.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install ta\n",
    "import ta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74933968",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "df1e0feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>vol</th>\n",
       "      <th>day</th>\n",
       "      <th>close_roc</th>\n",
       "      <th>close_log_roc</th>\n",
       "      <th>rsi</th>\n",
       "      <th>macd_signal</th>\n",
       "      <th>chaikin_money_flow</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txn_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1999-01-11</th>\n",
       "      <td>58.9</td>\n",
       "      <td>58.9</td>\n",
       "      <td>58.0</td>\n",
       "      <td>58.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003442</td>\n",
       "      <td>0.003436</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.003191</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-01-12</th>\n",
       "      <td>58.6</td>\n",
       "      <td>58.7</td>\n",
       "      <td>58.4</td>\n",
       "      <td>58.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003431</td>\n",
       "      <td>0.003425</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.011398</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-01-13</th>\n",
       "      <td>58.6</td>\n",
       "      <td>58.7</td>\n",
       "      <td>58.5</td>\n",
       "      <td>58.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.001708</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.023889</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-01-14</th>\n",
       "      <td>58.5</td>\n",
       "      <td>59.5</td>\n",
       "      <td>58.1</td>\n",
       "      <td>58.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.003413</td>\n",
       "      <td>0.003407</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.041546</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-01-23</th>\n",
       "      <td>59.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>58.6</td>\n",
       "      <td>58.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.001701</td>\n",
       "      <td>-0.001702</td>\n",
       "      <td>85.310605</td>\n",
       "      <td>0.059825</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            open  high   low  close  vol  day  close_roc  close_log_roc  \\\n",
       "txn_date                                                                  \n",
       "1999-01-11  58.9  58.9  58.0   58.3  0.0    0   0.003442       0.003436   \n",
       "1999-01-12  58.6  58.7  58.4   58.5  0.0    1   0.003431       0.003425   \n",
       "1999-01-13  58.6  58.7  58.5   58.6  0.0    2   0.001709       0.001708   \n",
       "1999-01-14  58.5  59.5  58.1   58.8  0.0    3   0.003413       0.003407   \n",
       "1999-01-23  59.0  59.0  58.6   58.7  0.0    5  -0.001701      -0.001702   \n",
       "\n",
       "                   rsi  macd_signal  chaikin_money_flow  \n",
       "txn_date                                                 \n",
       "1999-01-11  100.000000     0.003191                 0.0  \n",
       "1999-01-12  100.000000     0.011398                 0.0  \n",
       "1999-01-13  100.000000     0.023889                 0.0  \n",
       "1999-01-14  100.000000     0.041546                 0.0  \n",
       "1999-01-23   85.310605     0.059825                 0.0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/processed/company_id_94_processed.csv', parse_dates=True)\n",
    "data = data[['txn_date', \n",
    "             'open', 'high', 'low', \n",
    "             'close',\n",
    "             'vol', \n",
    "#              'month', \n",
    "             'day', \n",
    "#              'day_of_month'\n",
    "            ]].sort_values(by='txn_date')\n",
    "data['txn_date'] = pd.to_datetime(data['txn_date'])\n",
    "# data = data[data['txn_date']< '2020-03-01']\n",
    "data.set_index('txn_date', inplace=True, drop=True)\n",
    "data['close_roc'] = data['close'].pct_change()\n",
    "data['close_log_roc'] = np.log(1+data['close_roc'])\n",
    "data['rsi'] = ta.momentum.RSIIndicator(close=data['close'], fillna=True).rsi()\n",
    "data['macd_signal'] = ta.trend.MACD(close=data['close'], fillna=True).macd_signal()\n",
    "# data['macd_signal'] = ta.trend.MACD(close=data['close'], fillna=True).macd_signal()\n",
    "data['chaikin_money_flow'] = ta.volume.ChaikinMoneyFlowIndicator(high=data['high'], low=data['low'], close=data['close'], volume=data['vol'], fillna=True).chaikin_money_flow()\n",
    "data.dropna(inplace=True)\n",
    "# data = data.resample('W').mean()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75438105",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfd8de80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95b8c0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd324fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min(data.index), max(data.index), data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41b8e163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['chaikin_money_flow'].plot()\n",
    "# plt.xlabel('Date')\n",
    "# plt.ylabel('Price')\n",
    "# plt.legend(['Close Price'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fbb5313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['close_roc'].plot()\n",
    "# plt.xlabel('Date')\n",
    "# plt.ylabel('Close Price Rate Of Change')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "003e8f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['vol'].plot()\n",
    "# plt.xlabel('Date')\n",
    "# plt.ylabel('Trade Volume')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab4fce9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "def timeseries_evaluation_metrics_func(y_true, y_pred):\n",
    "    def mean_absolute_percentage_error(y_true, y_pred):\n",
    "        y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "        return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    print('Evaluation metric results:-')\n",
    "    print(f'MSE is : {metrics.mean_squared_error(y_true, y_pred)}')\n",
    "    print(f'MAE is : {metrics.mean_absolute_error(y_true, y_pred)}')\n",
    "    print(f'RMSE is : {np.sqrt(metrics.mean_squared_error(y_true, y_pred))}')\n",
    "    print(f'MAPE is : {mean_absolute_percentage_error(y_true, y_pred)}')\n",
    "    print(f'R2 is : {metrics.r2_score(y_true, y_pred)}',end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e694cfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_ts_data_prep(dataset, target, start, end, window, horizon):\n",
    "    X = []\n",
    "    y = []\n",
    "    start = start + window\n",
    "    if end is None:\n",
    "        end = len(dataset) - horizon\n",
    "    for i in range(start, end):\n",
    "        indices = range(i-window, i)\n",
    "        X.append(dataset[indices])\n",
    "        indicey = range(i+1, i+1+horizon)\n",
    "        y.append(target[indicey])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ce2ae611",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "y_scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "data_x = x_scaler.fit_transform(data)\n",
    "data_y = y_scaler.fit_transform(data[['close']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ec79b6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_window = 22\n",
    "horizon = 1\n",
    "TRAIN_SPLIT = int(len(data_x)*0.8)\n",
    "x_train_multi, y_train_multi = custom_ts_data_prep(data_x, data_y, 0, TRAIN_SPLIT, hist_window, horizon)\n",
    "x_val_multi, y_val_multi= custom_ts_data_prep(data_x, data_y, TRAIN_SPLIT, None, hist_window, horizon)\n",
    "split = int(len(x_val_multi)*0.5)\n",
    "x_val_multi, y_val_multi, x_test_multi, y_test_multi = x_val_multi[: split], y_val_multi[:split], x_val_multi[:-split], y_val_multi[:-split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5c99b420",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(x_train_multi.shape[0]  == y_train_multi.shape[0])\n",
    "assert(x_val_multi.shape[0]  == y_val_multi.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e181cef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_multi[:1], y_train_multi[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "618f6ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "BUFFER_SIZE = 150\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train_multi, y_train_multi))\n",
    "train_data = train_data.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "val_data = tf.data.Dataset.from_tensor_slices((x_val_multi, y_val_multi))\n",
    "val_data = val_data.batch(BATCH_SIZE).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9f57b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_multi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ae4665ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = Sequential([\n",
    "    LSTM(40, input_shape=x_train_multi.shape[-2:], return_sequences=True),\n",
    "    LSTM(units=40,return_sequences=True),\n",
    "    Dropout(0.1),\n",
    "    LSTM(units=40,return_sequences=True),\n",
    "    Dropout(0.1),\n",
    "    LSTM(units=20),\n",
    "#     Dropout(0.1),\n",
    "#     LSTM(units=40,return_sequences=True),\n",
    "#     Dropout(0.1),\n",
    "#     LSTM(units=40,return_sequences=True),\n",
    "#     Dropout(0.1),\n",
    "#     LSTM(units=40,return_sequences=True),\n",
    "#     Dropout(0.1),\n",
    "#     LSTM(units=40,return_sequences=True),\n",
    "#     Dropout(0.1),\n",
    "#     LSTM(units=40,return_sequences=True),\n",
    "#     Dropout(0.1),\n",
    "#     LSTM(units=40,return_sequences=True),\n",
    "#     Dropout(0.1),\n",
    "#     LSTM(units=40,return_sequences=True),\n",
    "#     Dropout(0.1),\n",
    "#     LSTM(units=40,return_sequences=True),\n",
    "#     Dropout(0.1),\n",
    "#     LSTM(units=40,return_sequences=True),\n",
    "#     Dropout(0.1),\n",
    "#     LSTM(units=40,return_sequences=True),\n",
    "#     Dropout(0.1),\n",
    "#     LSTM(units=15),\n",
    "    Dense(units=1)\n",
    "])\n",
    "lstm_model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3ec963c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = r'../models/LSTM_Multivariate.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2854,
   "id": "565f5178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "100/100 [==============================] - 16s 160ms/step - loss: 0.0653 - val_loss: 0.0136\n",
      "Epoch 2/150\n",
      "100/100 [==============================] - 13s 127ms/step - loss: 0.0155 - val_loss: 0.0110\n",
      "Epoch 3/150\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 0.0072 - val_loss: 0.0060\n",
      "Epoch 4/150\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.0064 - val_loss: 0.0036\n",
      "Epoch 5/150\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.0090 - val_loss: 0.0035\n",
      "Epoch 6/150\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 0.0054 - val_loss: 0.0024\n",
      "Epoch 7/150\n",
      "100/100 [==============================] - 13s 126ms/step - loss: 0.0056 - val_loss: 0.0016\n",
      "Epoch 8/150\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 0.0058 - val_loss: 2.5783e-04\n",
      "Epoch 9/150\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 0.0051 - val_loss: 2.1307e-04\n",
      "Epoch 10/150\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.0057 - val_loss: 5.3454e-04\n",
      "Epoch 11/150\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 0.0046 - val_loss: 2.2262e-04\n",
      "Epoch 12/150\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.0051 - val_loss: 2.8576e-04\n",
      "Epoch 13/150\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.0044 - val_loss: 0.0013\n",
      "Epoch 14/150\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 0.0046 - val_loss: 3.0735e-04\n",
      "Epoch 00014: early stopping\n"
     ]
    }
   ],
   "source": [
    "EVALUATION_INTERVAL = 100\n",
    "EPOCHS = 150\n",
    "history = lstm_model.fit(train_data,\n",
    "    epochs=EPOCHS,steps_per_epoch=EVALUATION_INTERVAL,validation_data=val_data, validation_steps=50,verbose =1,\n",
    "    callbacks =[tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5,\n",
    "    verbose=1, mode='min'),tf.keras.callbacks.ModelCheckpoint(model_path,monitor='val_loss', save_best_only=True, mode='min',\n",
    "    verbose=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "287db821",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1e96ad2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_140\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_373 (LSTM)              (None, 22, 40)            8320      \n",
      "_________________________________________________________________\n",
      "lstm_374 (LSTM)              (None, 22, 40)            12960     \n",
      "_________________________________________________________________\n",
      "dropout_195 (Dropout)        (None, 22, 40)            0         \n",
      "_________________________________________________________________\n",
      "lstm_375 (LSTM)              (None, 22, 40)            12960     \n",
      "_________________________________________________________________\n",
      "dropout_196 (Dropout)        (None, 22, 40)            0         \n",
      "_________________________________________________________________\n",
      "lstm_376 (LSTM)              (None, 20)                4880      \n",
      "_________________________________________________________________\n",
      "dense_141 (Dense)            (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 39,141\n",
      "Trainable params: 39,141\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2324059d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_model_loss_plot(history):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train loss', 'validation loss'], loc='upper left')\n",
    "#     plt.rcParams[\"figure.figsize\"] = [16,9]\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9dd94241",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "178ccc5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8f9068d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metric results:-\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-97d338e8ebce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtimeseries_evaluation_metrics_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-4421c496d8c3>\u001b[0m in \u001b[0;36mtimeseries_evaluation_metrics_func\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Evaluation metric results:-'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'MSE is : {metrics.mean_squared_error(y_true, y_pred)}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'MAE is : {metrics.mean_absolute_error(y_true, y_pred)}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'RMSE is : {np.sqrt(metrics.mean_squared_error(y_true, y_pred))}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mlpy38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mlpy38\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    333\u001b[0m     \u001b[1;36m0.825\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \"\"\"\n\u001b[1;32m--> 335\u001b[1;33m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0m\u001b[0;32m    336\u001b[0m         y_true, y_pred, multioutput)\n\u001b[0;32m    337\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mlpy38\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mlpy38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mlpy38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 720\u001b[1;33m             _assert_all_finite(array,\n\u001b[0m\u001b[0;32m    721\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0;32m    722\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mlpy38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    101\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m    102\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    104\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                     (type_err,\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2861,
   "id": "1d887be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.std(y_val_), np.mean(y_val_) #(4.016922584171439, 28.52873134328358)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2862,
   "id": "15249524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [y_scaler.inverse_transform(y[0].reshape(-1,1))[0][0] for y in y_val_multi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d7c10087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(scaler, y_val_multi, \n",
    "            y_test_multi, \n",
    "            result_inv_trans,\n",
    "            data, split):\n",
    "    a = pd.DataFrame([scaler.inverse_transform(y[0].reshape(-1,1))[0][0] \n",
    "                      for y in y_val_multi], index=np.array(data.index)[-2*split:-split])\n",
    "    b = pd.DataFrame([scaler.inverse_transform(y[0].reshape(-1,1))[0][0] \n",
    "                      for y in y_test_multi], index=data[-len(y_test_multi):].index)\n",
    "    c = pd.DataFrame([scaler.inverse_transform(np.array(y[0]).reshape(-1,1))[0][0] \n",
    "                      for y in result_inv_trans], index=data[-len(result_inv_trans):].index)\n",
    "    return a, b, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c073c960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_actual_vs_predicted_plot(a, b, c):    \n",
    "    plt.plot(a )\n",
    "    plt.plot(b)\n",
    "    plt.plot(c)\n",
    "    plt.title(\"Actual vs Predicted\")\n",
    "    plt.ylabel(\"Price Rate of Change\")\n",
    "    plt.legend(('val','Actual','predicted'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "edbbaaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rnn = Sequential([\n",
    "    SimpleRNN(15, input_shape=x_train_multi.shape[-2:], return_sequences=True),\n",
    "    Dense(1)\n",
    "])\n",
    "model_rnn.compile(optimizer='adam',loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "83b7bba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_data, val_data=val_data, \n",
    "                epochs=100,steps_per_epoch=100,\n",
    "               validation_steps=50, verbose=1, callbacks= None, model_path='../models/model.h5'):\n",
    "    if callbacks == None:\n",
    "        callbacks =[tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5,\n",
    "        verbose=1, mode='min'),tf.keras.callbacks.ModelCheckpoint(model_path,monitor='val_loss', save_best_only=True, mode='min',\n",
    "        verbose=0)]\n",
    "    history = model.fit(train_data, epochs=epochs,\n",
    "                        steps_per_epoch=steps_per_epoch,validation_data=val_data, \n",
    "                        validation_steps=validation_steps, verbose =verbose,\n",
    "                        callbacks=callbacks)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0051438c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 2s 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 1s 12ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 1s 12ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 1s 12ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 1s 12ms/step - loss: nan - val_loss: nan\n",
      "Epoch 00005: early stopping\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e1ba91ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lifecycle(model, data, split, train_data, x_test_multi, y_test_multi, y_scaler, y_val_multi):\n",
    "    history = train_model(model, train_data)\n",
    "    result_inv_trans = model.predict(x_test_multi)\n",
    "    a, b, c = process(y_scaler, y_val_multi, y_test_multi, result_inv_trans, data, split)\n",
    "    timeseries_evaluation_metrics_func(b.values, c.values)\n",
    "    show_model_loss_plot(history)\n",
    "    show_actual_vs_predicted_plot(a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfa01c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
